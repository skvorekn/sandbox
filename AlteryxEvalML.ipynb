{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial based on https://github.com/alteryx/evalml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO methodology ideas:\n",
    "* algorithmic bias\n",
    "\n",
    "### Workflow\n",
    "* semantic commits\n",
    "* git flow\n",
    "\n",
    "### Documentation\n",
    "* add problem_type argument to documentation\n",
    "* update woodwork documentation without the dreaded value slice error: https://woodwork.alteryx.com/en/stable/guides/statistical_insights.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import evalml\n",
    "from evalml.data_checks import HighlyNullDataCheck, NoVarianceDataCheck, ClassImbalanceDataCheck, TargetLeakageDataCheck, InvalidTargetDataCheck, IDColumnsDataCheck, MulticollinearityDataCheck, OutliersDataCheck\n",
    "from evalml.objectives import get_core_objectives\n",
    "from evalml.problem_types import detect_problem_type\n",
    "from evalml.utils import infer_feature_types\n",
    "\n",
    "from evalml.automl import AutoMLSearch\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "import woodwork as ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww.config.set_option('numeric_categorical_threshold', 2)\n",
    "ww.config.set_option('natural_language_threshold', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_kaggle_data():\n",
    "    # token stored in .kaggle/kaggle.json\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    \n",
    "    # must accept competition rules on kaggle.com\n",
    "    api.competition_download_files('titanic')\n",
    "    \n",
    "    zf = ZipFile('titanic.zip')\n",
    "    zf.extractall('data/')\n",
    "    zf.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_kaggle_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_checks(check, **kwargs):\n",
    "    results = check.validate(**kwargs)\n",
    "    for message in results['warnings']:\n",
    "        print(f\"Warning: {message['message']}\")\n",
    "    for message in results['errors']:\n",
    "        print(f\"Error: {message['message']}\")\n",
    "    \n",
    "def get_relevant_objectives(prob_type):\n",
    "    for objective in get_core_objectives(prob_type):\n",
    "        yield objective.name    \n",
    "    \n",
    "def check_data(x, y):\n",
    "    null_check = HighlyNullDataCheck(pct_null_threshold=0.5)\n",
    "    print_checks(null_check, X=x)\n",
    "    \n",
    "    nv_check = NoVarianceDataCheck()\n",
    "    print_checks(nv_check, X=x, y=y)\n",
    "    \n",
    "    ci_check = ClassImbalanceDataCheck(threshold=0.1)\n",
    "    print_checks(ci_check, X=x, y=y)\n",
    "    \n",
    "    tl_check = TargetLeakageDataCheck(pct_corr_threshold=0.7)\n",
    "    print_checks(tl_check, X=x, y=y)\n",
    "    \n",
    "    prob_type = str(detect_problem_type(y))\n",
    "    for obj in get_relevant_objectives(prob_type):\n",
    "        inv_check = InvalidTargetDataCheck(prob_type, obj)\n",
    "        print_checks(inv_check, X=x, y=y)\n",
    "    \n",
    "    id_check = IDColumnsDataCheck(id_threshold=0.9)\n",
    "    print_checks(id_check, X=x, y=y)\n",
    "    \n",
    "    mc_check = MulticollinearityDataCheck(threshold=0.8)\n",
    "    print_checks(mc_check, X=x, y=y)\n",
    "    \n",
    "    out_check = OutliersDataCheck()\n",
    "    print_checks(out_check, X=x, y=y)\n",
    "    \n",
    "    \n",
    "def process_kaggle_data(split_name, index = 'PassengerId', y = 'Survived'):\n",
    "    data = pd.read_csv(f'data/{split_name}.csv')\n",
    "    \n",
    "    x_df = data.drop([y, index, 'Name', 'Ticket'], axis = 1)\n",
    "    y_df = data[y]\n",
    "    print(detect_problem_type(y_df))\n",
    "    \n",
    "    check_data(x_df, y_df)\n",
    "    \n",
    "    return x_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = process_kaggle_data('train')\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X, y, problem_type = 'binary', test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLSearch(X_train, y_train, \n",
    "                      problem_type = 'binary',\n",
    "                      max_batches = 10,\n",
    "                      max_iterations = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.describe_pipeline(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.full_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = automl.best_pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox-dt0F7N9f",
   "language": "python",
   "name": "sandbox-dt0f7n9f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
